{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/gdrive')","metadata":{"id":"9sC6bP1lICCL","outputId":"6f844b1b-189d-484b-e1cb-9308ce79c9f0","execution":{"iopub.status.busy":"2021-12-05T10:38:46.950279Z","iopub.execute_input":"2021-12-05T10:38:46.950738Z","iopub.status.idle":"2021-12-05T10:38:46.970074Z","shell.execute_reply.started":"2021-12-05T10:38:46.950646Z","shell.execute_reply":"2021-12-05T10:38:46.969468Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n# !ln -s /content/gdrive/My\\ Drive/ /mydrive\n# !ls /mydrive","metadata":{"id":"r2WzQQXfIB_z","execution":{"iopub.status.busy":"2021-12-05T10:38:46.971571Z","iopub.execute_input":"2021-12-05T10:38:46.971879Z","iopub.status.idle":"2021-12-05T10:38:46.975469Z","shell.execute_reply.started":"2021-12-05T10:38:46.971845Z","shell.execute_reply":"2021-12-05T10:38:46.974770Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !cp -r  /mydrive/glove /content/glove/","metadata":{"id":"_OptF8ZLIB9L","execution":{"iopub.status.busy":"2021-12-05T10:38:46.976884Z","iopub.execute_input":"2021-12-05T10:38:46.977583Z","iopub.status.idle":"2021-12-05T10:38:46.985022Z","shell.execute_reply.started":"2021-12-05T10:38:46.977548Z","shell.execute_reply":"2021-12-05T10:38:46.984337Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import re\nimport os\nimport time\nimport numpy as np\nimport pandas as pd \nimport unicodedata\nimport tensorflow as tf\nimport tensorflow.keras as krs\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\nfrom tensorflow.keras.preprocessing.text import Tokenizer \nfrom tensorflow.keras.optimizers.schedules import LearningRateSchedule\nimport csv\n\nBUFFER_SIZE = 20000\nBATCH_SIZE = 64\nembedding_dim = 50","metadata":{"id":"kwQwhT0NtzuY","execution":{"iopub.status.busy":"2021-12-05T13:32:57.414966Z","iopub.execute_input":"2021-12-05T13:32:57.415380Z","iopub.status.idle":"2021-12-05T13:33:02.271809Z","shell.execute_reply.started":"2021-12-05T13:32:57.415273Z","shell.execute_reply":"2021-12-05T13:33:02.271018Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip freeze > requirements.txt","metadata":{"id":"DS9MnKQlJ97I","execution":{"iopub.status.busy":"2021-12-05T11:03:18.853983Z","iopub.execute_input":"2021-12-05T11:03:18.854227Z","iopub.status.idle":"2021-12-05T11:03:18.860655Z","shell.execute_reply.started":"2021-12-05T11:03:18.854194Z","shell.execute_reply":"2021-12-05T11:03:18.860005Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip install kaggle\n# !mkdir ~/.kaggle\n# !cp /content/kaggle.json ~/.kaggle/kaggle.json","metadata":{"id":"A6qNa1_xuEUZ","outputId":"81bf883a-0fc6-4e52-a38a-9bf12851a428","execution":{"iopub.status.busy":"2021-12-05T11:03:18.861768Z","iopub.execute_input":"2021-12-05T11:03:18.862109Z","iopub.status.idle":"2021-12-05T11:03:18.874322Z","shell.execute_reply.started":"2021-12-05T11:03:18.862076Z","shell.execute_reply":"2021-12-05T11:03:18.873654Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets download -d shashichander009/inshorts-news-data","metadata":{"id":"92Z7yiqIuESW","outputId":"7b4a4993-a4a8-4e3e-eaf8-e453a64a6aa7","execution":{"iopub.status.busy":"2021-12-05T11:03:18.877628Z","iopub.execute_input":"2021-12-05T11:03:18.877961Z","iopub.status.idle":"2021-12-05T11:03:18.883272Z","shell.execute_reply.started":"2021-12-05T11:03:18.877930Z","shell.execute_reply":"2021-12-05T11:03:18.882585Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !unzip /content/inshorts-news-data.zip","metadata":{"id":"Ksj4__jiuEP4","outputId":"8e22d28e-3461-42b2-c063-2cdb6c5aa509","execution":{"iopub.status.busy":"2021-12-05T11:03:18.885575Z","iopub.execute_input":"2021-12-05T11:03:18.885778Z","iopub.status.idle":"2021-12-05T11:03:18.891308Z","shell.execute_reply.started":"2021-12-05T11:03:18.885755Z","shell.execute_reply":"2021-12-05T11:03:18.890653Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:33:40.583590Z","iopub.execute_input":"2021-12-05T13:33:40.583905Z","iopub.status.idle":"2021-12-05T13:33:49.929024Z","shell.execute_reply.started":"2021-12-05T13:33:40.583866Z","shell.execute_reply":"2021-12-05T13:33:49.928156Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_unprocessed_news = pd.read_excel(\"../input/inshorts-news-data/Inshorts Cleaned Data.xlsx\")\ndata_unprocessed_news.head()","metadata":{"id":"b-bv-rdcuENH","outputId":"5cf38820-5474-4cab-e63e-f481d377a9dc","execution":{"iopub.status.busy":"2021-12-05T13:33:49.932434Z","iopub.execute_input":"2021-12-05T13:33:49.932659Z","iopub.status.idle":"2021-12-05T13:33:58.892690Z","shell.execute_reply.started":"2021-12-05T13:33:49.932632Z","shell.execute_reply":"2021-12-05T13:33:58.891991Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\ndata_unprocessed_news = shuffle(data_unprocessed_news,random_state=42)\ndata_unprocessed_news.head()","metadata":{"id":"YfF6721quEK1","outputId":"30663315-f6c3-446b-8386-c69a6880db7d","execution":{"iopub.status.busy":"2021-12-05T13:34:03.568914Z","iopub.execute_input":"2021-12-05T13:34:03.569369Z","iopub.status.idle":"2021-12-05T13:34:04.196526Z","shell.execute_reply.started":"2021-12-05T13:34:03.569330Z","shell.execute_reply":"2021-12-05T13:34:04.195575Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"summaries, longreview = pd.DataFrame(), pd.DataFrame()\nsummaries['short'] = data_unprocessed_news['Headline']#[:data_to_use]\nlongreview['long'] = data_unprocessed_news['Short']#[:data_to_use]\n(summaries.shape,longreview.shape)","metadata":{"id":"8kNxVnihuEBm","outputId":"5216afb8-5682-46eb-9f4f-385d2a5ac16c","execution":{"iopub.status.busy":"2021-12-05T13:34:08.826964Z","iopub.execute_input":"2021-12-05T13:34:08.827939Z","iopub.status.idle":"2021-12-05T13:34:08.858703Z","shell.execute_reply.started":"2021-12-05T13:34:08.827882Z","shell.execute_reply":"2021-12-05T13:34:08.858013Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"summaries.head()","metadata":{"id":"zlIEdmKfuD_I","outputId":"568b1436-4092-4897-8b67-587638881e24","execution":{"iopub.status.busy":"2021-12-05T13:34:10.620070Z","iopub.execute_input":"2021-12-05T13:34:10.620776Z","iopub.status.idle":"2021-12-05T13:34:10.628265Z","shell.execute_reply.started":"2021-12-05T13:34:10.620739Z","shell.execute_reply":"2021-12-05T13:34:10.627462Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"longreview.head()","metadata":{"id":"HGFzVs-luD8S","outputId":"de73b509-f05f-4262-af1b-cd3475213b51","execution":{"iopub.status.busy":"2021-12-05T13:34:11.885650Z","iopub.execute_input":"2021-12-05T13:34:11.886134Z","iopub.status.idle":"2021-12-05T13:34:11.895384Z","shell.execute_reply.started":"2021-12-05T13:34:11.886076Z","shell.execute_reply":"2021-12-05T13:34:11.893745Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def clean_words(sentence):\n    sentence = str(sentence).lower()\n    sentence = unicodedata.normalize('NFKD', sentence).encode('ascii', 'ignore').decode('utf-8', 'ignore') # for converting Ã© to e and other accented chars\n    sentence = re.sub(r\"http\\S+\",\"\",sentence)\n    sentence = re.sub(r\"there's\", \"there is\", sentence)\n    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n    sentence = re.sub(r\"he's\", \"he is\", sentence)\n    sentence = re.sub(r\"she's\", \"she is\", sentence)\n    sentence = re.sub(r\"it's\", \"it is\", sentence)\n    sentence = re.sub(r\"that's\", \"that is\", sentence)\n    sentence = re.sub(r\"what's\", \"that is\", sentence)\n    sentence = re.sub(r\"where's\", \"where is\", sentence)\n    sentence = re.sub(r\"how's\", \"how is\", sentence)\n    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n    sentence = re.sub(r\"won't\", \"will not\", sentence)\n    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n    sentence = re.sub(r\"n't\", \" not\", sentence)\n    sentence = re.sub(r\"n'\", \"ng\", sentence)\n    sentence = re.sub(r\"'bout\", \"about\", sentence)\n    sentence = re.sub(r\"'til\", \"until\", sentence)\n    sentence = re.sub(r\"\\\"\", \"\", sentence)\n    sentence = re.sub(r\"\\'\", \"\", sentence)\n    sentence = re.sub(r' s ', \"\",sentence)\n    sentence = re.sub(r\"&39\", \"\", sentence)\n    sentence = re.sub(r\"&34\", \"\", sentence) \n    sentence = re.sub(r\"[\\[\\]\\\\0-9()\\\"$#%/@;:<>{}`+=~|.!?,-]\", \"\", sentence)\n    sentence = re.sub(r\"&\", \"\", sentence)\n    sentence = re.sub(r\"\\\\n\", \"\", sentence)\n    sentence = sentence.strip()\n    return sentence","metadata":{"id":"axciokFquD5_","execution":{"iopub.status.busy":"2021-12-05T13:34:12.654829Z","iopub.execute_input":"2021-12-05T13:34:12.655408Z","iopub.status.idle":"2021-12-05T13:34:12.667644Z","shell.execute_reply.started":"2021-12-05T13:34:12.655367Z","shell.execute_reply":"2021-12-05T13:34:12.666933Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"summaries['short'] = summaries['short'].apply(lambda x: clean_words(x))\nlongreview['long'] = longreview['long'].apply(lambda x: clean_words(x))","metadata":{"id":"529Opbpkvarg","execution":{"iopub.status.busy":"2021-12-05T13:34:13.691520Z","iopub.execute_input":"2021-12-05T13:34:13.691772Z","iopub.status.idle":"2021-12-05T13:34:18.539917Z","shell.execute_reply.started":"2021-12-05T13:34:13.691742Z","shell.execute_reply":"2021-12-05T13:34:18.539161Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"start_token, end_token = '<startseq>' , '<endseq>'\nsummaries = summaries.apply(lambda x: start_token + ' ' + x + ' ' + end_token)\nsummaries.head()","metadata":{"id":"50o5fQlOvc1n","outputId":"05644d36-259a-45b0-9796-fbf568972683","execution":{"iopub.status.busy":"2021-12-05T13:34:18.542266Z","iopub.execute_input":"2021-12-05T13:34:18.542702Z","iopub.status.idle":"2021-12-05T13:34:18.580757Z","shell.execute_reply.started":"2021-12-05T13:34:18.542664Z","shell.execute_reply":"2021-12-05T13:34:18.580020Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_split = 0.1\n# train validation split\nsummaries_train = summaries[int(len(summaries)*val_split):]\nsummaries_val = summaries[:int(len(summaries)*val_split)]\nlongreview_train = longreview[int(len(summaries)*val_split):]\nlongreview_val = longreview[:int(len(summaries)*val_split)]\n\nlen(longreview_val),len(longreview_train)","metadata":{"id":"G_m7PUzwviNr","outputId":"04312b79-951e-4ad6-9af4-766ff03e1441","execution":{"iopub.status.busy":"2021-12-05T13:34:20.399301Z","iopub.execute_input":"2021-12-05T13:34:20.399844Z","iopub.status.idle":"2021-12-05T13:34:20.407709Z","shell.execute_reply.started":"2021-12-05T13:34:20.399807Z","shell.execute_reply":"2021-12-05T13:34:20.406912Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def max_length(shorts, longs, prct):\n    \n    length_longs = list(len(d.split()) for d in longs)\n    length_shorts = list(len(d.split()) for d in shorts)\n\n    print('percentile {} of length of news: {}'.format(prct,np.percentile(length_longs, prct)))\n    print('longest sentence: ', max(length_longs))\n    print()\n    print('percentile {} of length of summaries: {}'.format(prct,np.percentile(length_shorts, prct)))\n    print('longest sentence: ', max(length_shorts))\n    print()\n    return int(np.percentile(length_longs, prct)),int(np.percentile(length_shorts, prct))","metadata":{"id":"LqSFlLBXvp4X","execution":{"iopub.status.busy":"2021-12-05T13:34:22.955969Z","iopub.execute_input":"2021-12-05T13:34:22.956544Z","iopub.status.idle":"2021-12-05T13:34:22.965458Z","shell.execute_reply.started":"2021-12-05T13:34:22.956502Z","shell.execute_reply":"2021-12-05T13:34:22.962998Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"max_len_news, max_len_summary= max_length(summaries_train['short'].to_list(), longreview_train['long'].to_list(), 90)","metadata":{"id":"bYO2cu6XwJCG","outputId":"271c6693-9098-40b7-c729-e8a4492207a3","execution":{"iopub.status.busy":"2021-12-05T13:34:24.247932Z","iopub.execute_input":"2021-12-05T13:34:24.248221Z","iopub.status.idle":"2021-12-05T13:34:24.583448Z","shell.execute_reply.started":"2021-12-05T13:34:24.248188Z","shell.execute_reply":"2021-12-05T13:34:24.582581Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def create_vocab(shorts, longs = None, minimum_repeat = 3):\n\n    all_captions = []\n    for s in shorts:\n        all_captions.append(s)\n\n    word_counts = {}\n    nsents = 0\n    for sent in all_captions:\n        nsents += 1\n        for w in sent.split(' '):\n            word_counts[w] = word_counts.get(w, 0) + 1\n\n    vocab = [w for w in word_counts if word_counts[w] >= minimum_repeat]\n    \n    vocab = list(set(vocab))\n    return vocab","metadata":{"id":"eN-YXikRwI_j","execution":{"iopub.status.busy":"2021-12-05T13:34:27.300977Z","iopub.execute_input":"2021-12-05T13:34:27.301768Z","iopub.status.idle":"2021-12-05T13:34:27.310160Z","shell.execute_reply.started":"2021-12-05T13:34:27.301725Z","shell.execute_reply":"2021-12-05T13:34:27.309398Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"vocab_dec = create_vocab(summaries_train['short'].to_list(), minimum_repeat=5) # here we just use the words in vocabulary of summaries\n\nfor v in vocab_dec:\n    if len(v) == 1 and v!='a' and v!='i':\n        vocab_dec.remove(v) \n        \nvocab_dec = sorted(vocab_dec)[1:] \nvocab_dec[:10]","metadata":{"id":"DqwnQ8LGwI89","outputId":"0954b52e-6df8-4e38-dc18-8159b0d8eedd","execution":{"iopub.status.busy":"2021-12-05T13:34:27.717568Z","iopub.execute_input":"2021-12-05T13:34:27.718091Z","iopub.status.idle":"2021-12-05T13:34:27.897677Z","shell.execute_reply.started":"2021-12-05T13:34:27.718055Z","shell.execute_reply":"2021-12-05T13:34:27.896859Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"vocab_enc = create_vocab(longreview_train['long'].to_list(), minimum_repeat=3) \n\nfor v in vocab_enc:\n    if len(v) == 1 and v!='a' and v!='i':\n        vocab_enc.remove(v) \n        \nvocab_enc = sorted(vocab_enc)[1:] \nvocab_enc[:10]","metadata":{"id":"Qjm0VU18wzfZ","outputId":"9ca370f0-fd85-4c6c-bb4e-f8e17c47dfa8","execution":{"iopub.status.busy":"2021-12-05T13:34:27.926998Z","iopub.execute_input":"2021-12-05T13:34:27.927208Z","iopub.status.idle":"2021-12-05T13:34:28.836655Z","shell.execute_reply.started":"2021-12-05T13:34:27.927183Z","shell.execute_reply":"2021-12-05T13:34:28.835794Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"oov_token = '<UNK>'\nfilters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n' \n\ndocument_tokenizer = krs.preprocessing.text.Tokenizer(filters = filters,oov_token=oov_token)\nsummary_tokenizer = krs.preprocessing.text.Tokenizer(filters = filters,oov_token=oov_token)\n\ndocument_tokenizer.fit_on_texts(vocab_enc)\nsummary_tokenizer.fit_on_texts(vocab_dec)\n\nencoder_vocab_size = len(document_tokenizer.word_index) + 1 \ndecoder_vocab_size = len(summary_tokenizer.word_index) + 1\n\n# vocab_size\nencoder_vocab_size, decoder_vocab_size","metadata":{"id":"mxmK6sUrwzcy","outputId":"050aca4f-d300-4243-c566-b2ec1816e3da","execution":{"iopub.status.busy":"2021-12-05T13:34:40.044669Z","iopub.execute_input":"2021-12-05T13:34:40.045248Z","iopub.status.idle":"2021-12-05T13:34:40.378505Z","shell.execute_reply.started":"2021-12-05T13:34:40.045208Z","shell.execute_reply":"2021-12-05T13:34:40.377827Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"ixtoword_enc = {} # index to word dic\nixtoword_dec = {} # index to word dic\n\nwordtoix_enc = document_tokenizer.word_index \nixtoword_enc[0] = '<PAD0>' \nixtoword_dec[0] = '<PAD0>' \n\nfor w in document_tokenizer.word_index:\n    ixtoword_enc[document_tokenizer.word_index[w]] = w\n\nwordtoix_dec = summary_tokenizer.word_index \n\nfor w in summary_tokenizer.word_index:\n    ixtoword_dec[summary_tokenizer.word_index[w]] = w","metadata":{"id":"EU0EojpXwzak","execution":{"iopub.status.busy":"2021-12-05T13:34:40.936326Z","iopub.execute_input":"2021-12-05T13:34:40.937017Z","iopub.status.idle":"2021-12-05T13:34:40.959246Z","shell.execute_reply.started":"2021-12-05T13:34:40.936978Z","shell.execute_reply":"2021-12-05T13:34:40.958410Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"inputs = document_tokenizer.texts_to_sequences(longreview_train['long'])\ntargets = summary_tokenizer.texts_to_sequences(summaries_train['short'])\n\ninputs_val = document_tokenizer.texts_to_sequences(longreview_val['long'])\ntargets_val = summary_tokenizer.texts_to_sequences(summaries_val['short'])","metadata":{"id":"iyJjh0YiwzYv","execution":{"iopub.status.busy":"2021-12-05T13:34:44.832666Z","iopub.execute_input":"2021-12-05T13:34:44.833492Z","iopub.status.idle":"2021-12-05T13:34:47.827013Z","shell.execute_reply.started":"2021-12-05T13:34:44.833432Z","shell.execute_reply":"2021-12-05T13:34:47.826243Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"inputs = krs.preprocessing.sequence.pad_sequences(inputs, maxlen=max_len_news, padding='post', truncating='post')\ntargets = krs.preprocessing.sequence.pad_sequences(targets, maxlen=max_len_summary, padding='post', truncating='post')\n\ninputs_val = krs.preprocessing.sequence.pad_sequences(inputs_val, maxlen=max_len_news, padding='post', truncating='post')\ntargets_val = krs.preprocessing.sequence.pad_sequences(targets_val, maxlen=max_len_summary, padding='post', truncating='post')","metadata":{"id":"Yf11eOUFwzWj","execution":{"iopub.status.busy":"2021-12-05T13:34:47.828827Z","iopub.execute_input":"2021-12-05T13:34:47.829082Z","iopub.status.idle":"2021-12-05T13:34:49.071898Z","shell.execute_reply.started":"2021-12-05T13:34:47.829049Z","shell.execute_reply":"2021-12-05T13:34:49.071144Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((inputs,targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ndataset_val = tf.data.Dataset.from_tensor_slices((inputs_val,targets_val)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE*2)","metadata":{"id":"r7JI38oswzUB","execution":{"iopub.status.busy":"2021-12-05T13:34:49.073206Z","iopub.execute_input":"2021-12-05T13:34:49.073449Z","iopub.status.idle":"2021-12-05T13:34:51.399845Z","shell.execute_reply.started":"2021-12-05T13:34:49.073417Z","shell.execute_reply":"2021-12-05T13:34:51.399128Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"longreview_val.reset_index(inplace=True, drop=True)\nsummaries_val.reset_index(inplace=True, drop=True)\nlongreview_train.reset_index(inplace=True, drop=True)\nsummaries_train.reset_index(inplace=True, drop=True)","metadata":{"id":"Shu93RYzwzRi","execution":{"iopub.status.busy":"2021-12-05T13:34:51.401705Z","iopub.execute_input":"2021-12-05T13:34:51.401980Z","iopub.status.idle":"2021-12-05T13:34:51.410267Z","shell.execute_reply.started":"2021-12-05T13:34:51.401946Z","shell.execute_reply":"2021-12-05T13:34:51.409567Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef hist(history):\n    plt.title('Loss')\n\n    x= [i[0] for i in history['val']]\n    y=[i[1] for i in history['val']]\n    plt.plot(x,y,'x-')\n    \n    x= [i[0] for i in history['train']]\n    y=[i[1] for i in history['train']]    \n    plt.plot(x,y,'o-')\n\n    plt.legend(['validation','train'])\n    plt.show()\n    print('smallest val loss:', sorted(history['val'],key=lambda x: x[1])[0])","metadata":{"id":"FXPdnBqjwzPt","execution":{"iopub.status.busy":"2021-12-05T13:34:51.411519Z","iopub.execute_input":"2021-12-05T13:34:51.411782Z","iopub.status.idle":"2021-12-05T13:34:51.421384Z","shell.execute_reply.started":"2021-12-05T13:34:51.411746Z","shell.execute_reply":"2021-12-05T13:34:51.420637Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# test_sen = ['Hello How are you ?', 'Hello', 'How are you', 'I am fine', 'Thank You']\n# test_seq = document_tokenizer.texts_to_sequences(test_sen)\n# test_seq","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:09:43.953231Z","iopub.execute_input":"2021-12-05T11:09:43.953871Z","iopub.status.idle":"2021-12-05T11:09:43.961557Z","shell.execute_reply.started":"2021-12-05T11:09:43.953829Z","shell.execute_reply":"2021-12-05T11:09:43.960646Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# test_sen = ['Hello How are you ?', 'Hello', 'How are you', 'I am fine', 'Thank You']\n# test_seq = summary_tokenizer.texts_to_sequences(test_sen)\n# test_seq","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:10:52.677141Z","iopub.execute_input":"2021-12-05T11:10:52.677465Z","iopub.status.idle":"2021-12-05T11:10:52.683793Z","shell.execute_reply.started":"2021-12-05T11:10:52.677416Z","shell.execute_reply":"2021-12-05T11:10:52.683042Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def scaled_dot_product_attention(q, k, v, mask):\n    matmul_qk = tf.matmul(q, k, transpose_b=True)\n\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    if mask is not None:\n        scaled_attention_logits += (mask * -1e9)  \n\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n\n    output = tf.matmul(attention_weights, v)\n    return output, attention_weights","metadata":{"id":"YkNHQoaGwzNK","execution":{"iopub.status.busy":"2021-12-05T13:35:25.759260Z","iopub.execute_input":"2021-12-05T13:35:25.759533Z","iopub.status.idle":"2021-12-05T13:35:25.765317Z","shell.execute_reply.started":"2021-12-05T13:35:25.759502Z","shell.execute_reply":"2021-12-05T13:35:25.764649Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(krs.layers.Layer):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n\n        assert d_model % self.num_heads == 0\n\n        self.depth = d_model // self.num_heads # The dimensions of Q, K, V are called depth\n\n        # the input of these 3 layers are the same: X\n        self.wq = krs.layers.Dense(d_model,kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))\n        self.wk = krs.layers.Dense(d_model,kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))\n        self.wv = krs.layers.Dense(d_model,kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))\n\n        self.dense = tf.keras.layers.Dense(d_model,kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))\n    \n    # reshape the Q,K,V \n    def split_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n    \n    def call(self, v, k, q, mask):\n        batch_size = tf.shape(q)[0]\n        \n        # learn the Q,K,V matrices (the layers' weightes)\n        q = self.wq(q)\n        k = self.wk(k)\n        v = self.wv(v)\n        \n        # reshape them\n        q = self.split_heads(q, batch_size)\n        k = self.split_heads(k, batch_size)\n        v = self.split_heads(v, batch_size)\n\n        scaled_attention, attention_weights = scaled_dot_product_attention(\n            q, k, v, mask)\n\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n        \n        # the last dens layer expect one vector so we use concat\n        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n        output = self.dense(concat_attention)\n            \n        return output, attention_weights","metadata":{"id":"E6NgqvxawzHM","execution":{"iopub.status.busy":"2021-12-05T13:35:26.307224Z","iopub.execute_input":"2021-12-05T13:35:26.307759Z","iopub.status.idle":"2021-12-05T13:35:26.319726Z","shell.execute_reply.started":"2021-12-05T13:35:26.307720Z","shell.execute_reply":"2021-12-05T13:35:26.319050Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_angles(position, i, d_model):\n    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n    return position * angle_rates\n\ndef positional_encoding(position, d_model):\n    angle_rads = get_angles(\n        np.arange(position)[:, np.newaxis],\n        np.arange(d_model)[np.newaxis, :],\n        d_model\n        )\n\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)","metadata":{"id":"AlxIvaXXwzDg","execution":{"iopub.status.busy":"2021-12-05T13:35:27.124612Z","iopub.execute_input":"2021-12-05T13:35:27.125215Z","iopub.status.idle":"2021-12-05T13:35:27.134317Z","shell.execute_reply.started":"2021-12-05T13:35:27.125176Z","shell.execute_reply":"2021-12-05T13:35:27.133612Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def make_embedding_layer(vocab_len, wordtoix, embedding_dim=200, glove=True, glove_path= '../input/glove-embedding'):\n    if glove == False:\n        print('Just a zero matrix loaded')\n        embedding_matrix = np.zeros((vocab_len, embedding_dim)) \n    else:\n        \n        print('Loading glove...')\n        glove_dir = glove_path\n        embeddings_index = {} \n        f = open(os.path.join(glove_dir, 'glove.6B.'+str(embedding_dim)+'d.txt'), encoding=\"utf-8\")\n        for line in f:\n            values = line.split()\n            word = values[0]\n            coefs = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = coefs\n        f.close()\n        \n        embedding_matrix = np.zeros((vocab_len, embedding_dim)) # to import as weights for Keras Embedding layer\n        for word, i in wordtoix.items():\n            embedding_vector = embeddings_index.get(word)\n            if embedding_vector is not None:\n                # Words not found in the embedding index will be all zeros\n                embedding_matrix[i] = embedding_vector\n        \n        print(\"GloVe \",embedding_dim, ' loaded!')\n\n    embedding_layer = Embedding(vocab_len, embedding_dim, mask_zero=True, trainable=False) \n    embedding_layer.build((None,))\n    embedding_layer.set_weights([embedding_matrix])\n    return embedding_layer","metadata":{"id":"W92xTIMWwzA6","execution":{"iopub.status.busy":"2021-12-05T13:35:27.806651Z","iopub.execute_input":"2021-12-05T13:35:27.807176Z","iopub.status.idle":"2021-12-05T13:35:27.816707Z","shell.execute_reply.started":"2021-12-05T13:35:27.807135Z","shell.execute_reply":"2021-12-05T13:35:27.815836Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"embeddings_encoder = make_embedding_layer(encoder_vocab_size, wordtoix_enc, embedding_dim=embedding_dim, glove=True)\nembeddings_decoder = make_embedding_layer(decoder_vocab_size, wordtoix_dec, embedding_dim=embedding_dim, glove=True)","metadata":{"id":"UCeJRTgXwy-4","outputId":"6c07f0ba-ced5-4ec1-e264-370bb9732bbc","execution":{"iopub.status.busy":"2021-12-05T13:35:28.743077Z","iopub.execute_input":"2021-12-05T13:35:28.743809Z","iopub.status.idle":"2021-12-05T13:35:47.419204Z","shell.execute_reply.started":"2021-12-05T13:35:28.743772Z","shell.execute_reply":"2021-12-05T13:35:47.418305Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# hyper-params\ninit_lr = 1e-3\nlmbda_l2 = 0.1\nd_out_rate = 0.1 # tested 0.4, 0.3, 0.1 values this 0.1 seems to be the best\nnum_layers = 4 # chaged from 4 to 5 to learn better\nd_model = embedding_dim # d_model is the representation dimension or embedding dimension of a word (usually in the range 128â512)\ndff = 512 # number of neurons in feed forward network\nnum_heads = 5 # first it was 8 i chenged it to 10 to use embd =300d","metadata":{"id":"YR5i2qegwy8M","execution":{"iopub.status.busy":"2021-12-05T13:35:47.420775Z","iopub.execute_input":"2021-12-05T13:35:47.421589Z","iopub.status.idle":"2021-12-05T13:35:47.427539Z","shell.execute_reply.started":"2021-12-05T13:35:47.421544Z","shell.execute_reply":"2021-12-05T13:35:47.426732Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def point_wise_feed_forward_network(d_model, dff):\n    return krs.Sequential([\n        krs.layers.Dense(dff, activation='relu',kernel_regularizer=krs.regularizers.l2(l=lmbda_l2)),\n        krs.layers.Dense(d_model,kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))\n    ])","metadata":{"id":"_G8OxXO752n7","execution":{"iopub.status.busy":"2021-12-05T13:35:49.842456Z","iopub.execute_input":"2021-12-05T13:35:49.843234Z","iopub.status.idle":"2021-12-05T13:35:49.850702Z","shell.execute_reply.started":"2021-12-05T13:35:49.843197Z","shell.execute_reply":"2021-12-05T13:35:49.849965Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(krs.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=d_out_rate):\n        super(EncoderLayer, self).__init__()\n\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = krs.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = krs.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = krs.layers.Dropout(rate)\n        self.dropout2 = krs.layers.Dropout(rate)\n   \n    # it has 1 layer of multi-headed attention\n    def call(self, x, training, mask):\n        attn_output, _ = self.mha(x, x, x, mask)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(x + attn_output)\n\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        out2 = self.layernorm2(out1 + ffn_output)\n\n        return out2","metadata":{"id":"7DSKrS3H52l5","execution":{"iopub.status.busy":"2021-12-05T13:35:50.390596Z","iopub.execute_input":"2021-12-05T13:35:50.391394Z","iopub.status.idle":"2021-12-05T13:35:50.399741Z","shell.execute_reply.started":"2021-12-05T13:35:50.391346Z","shell.execute_reply":"2021-12-05T13:35:50.398930Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(krs.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=d_out_rate):\n        super(DecoderLayer, self).__init__()\n\n        self.mha1 = MultiHeadAttention(d_model, num_heads)\n        self.mha2 = MultiHeadAttention(d_model, num_heads)\n\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = krs.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = krs.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = krs.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = krs.layers.Dropout(rate)\n        self.dropout2 = krs.layers.Dropout(rate)\n        self.dropout3 = krs.layers.Dropout(rate)\n    \n    # it has 2 layers of multi-headed attention\n    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n        attn1 = self.dropout1(attn1, training=training)\n        out1 = self.layernorm1(attn1 + x)\n\n        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n        attn2 = self.dropout2(attn2, training=training)\n        out2 = self.layernorm2(attn2 + out1)\n\n        ffn_output = self.ffn(out2)\n        ffn_output = self.dropout3(ffn_output, training=training)\n        out3 = self.layernorm3(ffn_output + out2)\n\n        return out3, attn_weights_block1, attn_weights_block2","metadata":{"id":"eQE1cLO452je","execution":{"iopub.status.busy":"2021-12-05T13:35:50.835837Z","iopub.execute_input":"2021-12-05T13:35:50.838135Z","iopub.status.idle":"2021-12-05T13:35:50.848275Z","shell.execute_reply.started":"2021-12-05T13:35:50.838081Z","shell.execute_reply":"2021-12-05T13:35:50.846924Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Encoder(krs.layers.Layer):\n    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=d_out_rate):\n        super(Encoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n\n        self.embedding = embeddings_encoder\n        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n\n        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n\n        self.dropout = krs.layers.Dropout(rate)\n        self.dropout_embd = krs.layers.Dropout(rate)\n        \n    def call(self, x, training, mask):\n        seq_len = tf.shape(x)[1]\n\n        x = self.embedding(x)\n        x = self.dropout_embd(x, training=training) # dropout added to encoder input changed from nothing to this\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)\n    \n        for i in range(self.num_layers):\n            x = self.enc_layers[i](x, training, mask)\n    \n        return x","metadata":{"id":"TDbBm3sm52hG","execution":{"iopub.status.busy":"2021-12-05T13:35:51.283853Z","iopub.execute_input":"2021-12-05T13:35:51.284487Z","iopub.status.idle":"2021-12-05T13:35:51.295710Z","shell.execute_reply.started":"2021-12-05T13:35:51.284448Z","shell.execute_reply":"2021-12-05T13:35:51.293762Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Decoder(krs.layers.Layer):\n    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=d_out_rate):\n        super(Decoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n\n        self.embedding = embeddings_decoder\n        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n\n        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)] # a list of decoder layers\n        self.dropout = krs.layers.Dropout(rate)\n    \n    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n        seq_len = tf.shape(x)[1]\n        attention_weights = {}\n\n        x = self.embedding(x)\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)\n\n        for i in range(self.num_layers):\n            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask) # enc_output is fed into it\n\n            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n    \n        return x, attention_weights","metadata":{"id":"yXnvnigy52dw","execution":{"iopub.status.busy":"2021-12-05T13:35:51.761182Z","iopub.execute_input":"2021-12-05T13:35:51.762286Z","iopub.status.idle":"2021-12-05T13:35:51.772604Z","shell.execute_reply.started":"2021-12-05T13:35:51.762235Z","shell.execute_reply":"2021-12-05T13:35:51.771795Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# class Transformer(krs.Model):\n#   def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,target_vocab_size, pe_input, pe_target, rate=d_out_rate):\n#     super(Transformer, self).__init__()\n#     self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n#     self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n#     self.final_layer = krs.layers.Dense(target_vocab_size, kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))        \n\n#   def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n#     enc_output = self.encoder(inp, training, enc_padding_mask)  \n#     dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n#     final_output = self.final_layer(dec_output)\n#     return final_output, attention_weights","metadata":{"id":"wOQcwIp352ai","execution":{"iopub.status.busy":"2021-12-05T13:35:52.231824Z","iopub.execute_input":"2021-12-05T13:35:52.232441Z","iopub.status.idle":"2021-12-05T13:35:52.237783Z","shell.execute_reply.started":"2021-12-05T13:35:52.232403Z","shell.execute_reply":"2021-12-05T13:35:52.237017Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Transformer(krs.Model):\n    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n                                     target_vocab_size, pe_input, pe_target, rate=d_out_rate):\n        super(Transformer, self).__init__()\n        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n        self.final_layer = krs.layers.Dense(target_vocab_size, kernel_regularizer=krs.regularizers.l2(l=lmbda_l2))\n        \n        \n    # training argument is used in dropout inputs\n    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n        enc_output = self.encoder(inp, training, enc_padding_mask)\n        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n        final_output = self.final_layer(dec_output)\n        return final_output, attention_weights","metadata":{"id":"a3D4sxiLRV9v","execution":{"iopub.status.busy":"2021-12-05T13:35:52.678901Z","iopub.execute_input":"2021-12-05T13:35:52.679183Z","iopub.status.idle":"2021-12-05T13:35:52.691411Z","shell.execute_reply.started":"2021-12-05T13:35:52.679149Z","shell.execute_reply":"2021-12-05T13:35:52.690530Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def create_padding_mask(seq):\n    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n    return seq[:, tf.newaxis, tf.newaxis, :]\n\n\ndef create_look_ahead_mask(size):\n    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    return mask","metadata":{"id":"aiKYKB9C52X4","execution":{"iopub.status.busy":"2021-12-05T13:35:53.440514Z","iopub.execute_input":"2021-12-05T13:35:53.441278Z","iopub.status.idle":"2021-12-05T13:35:53.447404Z","shell.execute_reply.started":"2021-12-05T13:35:53.441223Z","shell.execute_reply":"2021-12-05T13:35:53.446609Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def create_masks(inp, tar):\n    enc_padding_mask = create_padding_mask(inp)\n    dec_padding_mask = create_padding_mask(inp)\n\n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    dec_target_padding_mask = create_padding_mask(tar)\n        \n    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n  \n    return enc_padding_mask, combined_mask, dec_padding_mask","metadata":{"id":"8rVBLdtnwy5l","execution":{"iopub.status.busy":"2021-12-05T13:35:54.001373Z","iopub.execute_input":"2021-12-05T13:35:54.003301Z","iopub.status.idle":"2021-12-05T13:35:54.008393Z","shell.execute_reply.started":"2021-12-05T13:35:54.003249Z","shell.execute_reply":"2021-12-05T13:35:54.007648Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"transformer = Transformer(\n    num_layers, \n    d_model, \n    num_heads, \n    dff,\n    encoder_vocab_size, \n    decoder_vocab_size, \n    pe_input=max_len_news,\n    pe_target=max_len_summary,\n)","metadata":{"id":"sCpkddoRhji1","execution":{"iopub.status.busy":"2021-12-05T13:35:54.926006Z","iopub.execute_input":"2021-12-05T13:35:54.926864Z","iopub.status.idle":"2021-12-05T13:35:55.044617Z","shell.execute_reply.started":"2021-12-05T13:35:54.926820Z","shell.execute_reply":"2021-12-05T13:35:55.043858Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"bFV1clKJRJG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule = krs.optimizers.schedules.ExponentialDecay(initial_learning_rate=init_lr, decay_steps=4000, decay_rate=0.95)","metadata":{"id":"5JVol6IySN6C","execution":{"iopub.status.busy":"2021-12-05T13:35:57.106230Z","iopub.execute_input":"2021-12-05T13:35:57.108302Z","iopub.status.idle":"2021-12-05T13:35:57.113138Z","shell.execute_reply.started":"2021-12-05T13:35:57.108247Z","shell.execute_reply":"2021-12-05T13:35:57.112166Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"optimizer2 = Adam(lr_schedule , beta_1=0.9, beta_2=0.98, epsilon=1e-9) # changed to init\nloss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') # added softmax changed from_logits to false","metadata":{"id":"SF-wTidUSN4h","execution":{"iopub.status.busy":"2021-12-05T13:35:57.522062Z","iopub.execute_input":"2021-12-05T13:35:57.522366Z","iopub.status.idle":"2021-12-05T13:35:57.530275Z","shell.execute_reply.started":"2021-12-05T13:35:57.522332Z","shell.execute_reply":"2021-12-05T13:35:57.529384Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def loss_function(real,pred,l2=False):\n  \n  if l2:\n    lambda_ = 0.0001\n    l2_norms = [tf.nn.l2_loss(v) for v in transformer.trainable_variables]\n    l2_norm = tf.reduce_sum(l2_norms)\n    l2_value = lambda_ * l2_norm\n    loss_ = loss_object(real, pred) + l2_value\n  \n  else:\n    loss_ = loss_object(real,pred)\n  \n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  mask = tf.cast(mask,dtype=loss_.dtype)\n  loss_ *= mask\n\n  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)","metadata":{"id":"C2kXHiY-SN27","execution":{"iopub.status.busy":"2021-12-05T13:35:58.035941Z","iopub.execute_input":"2021-12-05T13:35:58.036489Z","iopub.status.idle":"2021-12-05T13:35:58.043785Z","shell.execute_reply.started":"2021-12-05T13:35:58.036445Z","shell.execute_reply":"2021-12-05T13:35:58.042967Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"checkpoint_path4 =\"checkpoints4\"\nckpt4 = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer2)\nckpt_manager4 = tf.train.CheckpointManager(ckpt4, checkpoint_path4, max_to_keep=100)","metadata":{"id":"nJQk_gbpSN1J","execution":{"iopub.status.busy":"2021-12-05T13:35:58.839791Z","iopub.execute_input":"2021-12-05T13:35:58.840354Z","iopub.status.idle":"2021-12-05T13:35:58.849009Z","shell.execute_reply.started":"2021-12-05T13:35:58.840314Z","shell.execute_reply":"2021-12-05T13:35:58.848067Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def evaluate(input_document):\n    input_document = document_tokenizer.texts_to_sequences([input_document])\n    input_document = krs.preprocessing.sequence.pad_sequences(input_document, maxlen=max_len_news, padding='post', truncating='post')\n    \n    encoder_input = tf.expand_dims(input_document[0], 0)\n\n    decoder_input = [summary_tokenizer.word_index[start_token]]\n    output = tf.expand_dims(decoder_input, 0)\n    \n    for i in range(max_len_summary):\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n\n        predictions, attention_weights = transformer(\n            encoder_input, \n            output,\n            False,\n            enc_padding_mask,\n            combined_mask,\n            dec_padding_mask\n        )\n\n        predictions = predictions[: ,-1:, :]\n        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n        # stop prediciting if it reached end_token\n        if predicted_id == summary_tokenizer.word_index[end_token]:\n            return tf.squeeze(output, axis=0), attention_weights\n\n        output = tf.concat([output, predicted_id], axis=-1)\n    return tf.squeeze(output, axis=0), attention_weights","metadata":{"id":"pp9MNN_5SNxW","execution":{"iopub.status.busy":"2021-12-05T13:36:00.929082Z","iopub.execute_input":"2021-12-05T13:36:00.929661Z","iopub.status.idle":"2021-12-05T13:36:00.940103Z","shell.execute_reply.started":"2021-12-05T13:36:00.929623Z","shell.execute_reply":"2021-12-05T13:36:00.939104Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def summarize(input_document):\n    summarized = evaluate(input_document=input_document)[0].numpy()\n    summarized = np.expand_dims(summarized[1:], 0)  \n    return summary_tokenizer.sequences_to_texts(summarized)[0]  ","metadata":{"id":"9Flvwe6FSNuF","execution":{"iopub.status.busy":"2021-12-05T13:36:02.306868Z","iopub.execute_input":"2021-12-05T13:36:02.307169Z","iopub.status.idle":"2021-12-05T13:36:02.315390Z","shell.execute_reply.started":"2021-12-05T13:36:02.307138Z","shell.execute_reply":"2021-12-05T13:36:02.314552Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def validate():\n    print('validation started ...')\n    val_loss.reset_states()\n    \n    for (batch, (inp, tar)) in enumerate(dataset_val):    \n        tar_inp = tar[:, :-1] \n        tar_real = tar[:, 1:]\n\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n\n        # Operations are recorded if they are executed within this context manager\n        # and at least one of their inputs is being \"watched\". Trainable variables are automatically watched\n        predictions, _ = transformer(\n            inp, tar_inp, \n            False, \n            enc_padding_mask, \n            combined_mask, \n            dec_padding_mask\n        )\n        \n        loss = loss_function(tar_real, predictions)\n        val_loss(loss)\n    print('\\n* Validation loss: {} '.format(val_loss.result()) )\n    return val_loss.result()","metadata":{"id":"vpTWpJsqSNrb","execution":{"iopub.status.busy":"2021-12-05T13:36:02.852706Z","iopub.execute_input":"2021-12-05T13:36:02.853404Z","iopub.status.idle":"2021-12-05T13:36:02.862383Z","shell.execute_reply.started":"2021-12-05T13:36:02.853364Z","shell.execute_reply":"2021-12-05T13:36:02.861619Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"@tf.function \ndef train_step(inp, tar):\n    tar_inp = tar[:, :-1] # <startseq> hi im moein\n    tar_real = tar[:, 1:] # hi im moein <endseq>\n\n    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n    \n    # Operations are recorded if they are executed within this context manager\n    # and at least one of their inputs is being \"watched\". Trainable variables are automatically watched\n    with tf.GradientTape() as tape:\n        predictions, _ = transformer(\n            inp, tar_inp, \n            True, \n            enc_padding_mask, \n            combined_mask, \n            dec_padding_mask\n        )\n        loss = loss_function(tar_real, predictions)\n\n    gradients = tape.gradient(loss, transformer.trainable_variables)    \n    optimizer2.apply_gradients(zip(gradients, transformer.trainable_variables))\n    \n    # mean the loss with new computed  loss of the step\n    train_loss(loss)","metadata":{"id":"0d-Kt-LWSNo3","execution":{"iopub.status.busy":"2021-12-05T13:36:03.593273Z","iopub.execute_input":"2021-12-05T13:36:03.593593Z","iopub.status.idle":"2021-12-05T13:36:03.602889Z","shell.execute_reply.started":"2021-12-05T13:36:03.593558Z","shell.execute_reply":"2021-12-05T13:36:03.601885Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"history={'val':[],'train':[]}\nEPOCHS = 300\nnot_progressing = 0\n# Computes the (weighted) mean of the given loss values.\ntrain_loss = krs.metrics.Mean(name='train_loss')\nval_loss = krs.metrics.Mean(name='val_loss')","metadata":{"id":"U4F3biJ_SNmN","execution":{"iopub.status.busy":"2021-12-05T13:36:04.477073Z","iopub.execute_input":"2021-12-05T13:36:04.477804Z","iopub.status.idle":"2021-12-05T13:36:04.492758Z","shell.execute_reply.started":"2021-12-05T13:36:04.477766Z","shell.execute_reply":"2021-12-05T13:36:04.491684Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"params = {\n'lmbda_l2' : lmbda_l2,\n'd_out_rate' :d_out_rate,\n'num_layers' : num_layers ,\n'd_model' : d_model  ,\n'dff' : dff ,\n'num_heads' : num_heads,\n'init_lr':init_lr}\nparams","metadata":{"id":"dUagcr3PY3Og","outputId":"b11f85e9-23b6-46d5-d3ad-975b97d76d4a","execution":{"iopub.status.busy":"2021-12-05T13:36:05.141686Z","iopub.execute_input":"2021-12-05T13:36:05.142479Z","iopub.status.idle":"2021-12-05T13:36:05.150178Z","shell.execute_reply.started":"2021-12-05T13:36:05.142430Z","shell.execute_reply":"2021-12-05T13:36:05.149300Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"ep = 1\nbest_val_loss = np.inf\ni1,i2,i3,i4 = np.random.randint(len(summaries_val)),np.random.randint(len(summaries_val)),np.random.randint(len(summaries_val)),np.random.randint(len(summaries_val))","metadata":{"id":"kzRvFLs3Y5DH","execution":{"iopub.status.busy":"2021-12-05T13:36:08.371196Z","iopub.execute_input":"2021-12-05T13:36:08.371737Z","iopub.status.idle":"2021-12-05T13:36:08.378280Z","shell.execute_reply.started":"2021-12-05T13:36:08.371699Z","shell.execute_reply":"2021-12-05T13:36:08.375847Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"print(params)\nprint('#'*40)\n\nfor epoch in range(ep,EPOCHS+1):\n    ep = epoch\n    start = time.time()\n\n    train_loss.reset_states()\n  \n    for (batch, (inp, tar)) in enumerate(dataset):\n        \n        train_step(inp, tar)\n    \n        if batch % 150 == 0:\n            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch , batch, train_loss.result()))\n                  \n    print()\n    print(summarize(clean_words(longreview_val['long'][i1])))\n    print(summarize(clean_words(longreview_val['long'][i2])))\n    print(summarize(clean_words(longreview_val['long'][i3])))\n    print(summarize(clean_words(longreview_val['long'][i4])))\n    print()\n    \n    val_loss_ = validate().numpy()\n    history['val'].append((epoch,val_loss_))\n    print ('\\n* Train Loss {:.4f}'.format(train_loss.result()))\n    history['train'].append((epoch,train_loss.result().numpy()))\n    \n    \n    if best_val_loss-val_loss_ > 0.1:\n        ckpt_save_path4 = ckpt_manager4.save()\n        print ('\\nSaving checkpoint for epoch {} at {}'.format(epoch, ckpt_save_path4))  \n        best_val_loss = val_loss_\n    \n    hist(history)\n    print('Current Lr: ',optimizer2._decayed_lr('float32').numpy())\n    print ('\\nTime taken for this epoch: {:.2f} secs\\n'.format(time.time() - start))\n    print('='*40)","metadata":{"id":"wR6sTajAY_sN","outputId":"6547896e-f48f-49b6-e4e9-236114e52d2c","execution":{"iopub.status.busy":"2021-12-05T13:36:13.461746Z","iopub.execute_input":"2021-12-05T13:36:13.462179Z","iopub.status.idle":"2021-12-05T15:40:20.726414Z","shell.execute_reply.started":"2021-12-05T13:36:13.462136Z","shell.execute_reply":"2021-12-05T15:40:20.725671Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"hist(history)","metadata":{"id":"YvlrgpowZKdN","execution":{"iopub.status.busy":"2021-12-05T15:40:49.466087Z","iopub.execute_input":"2021-12-05T15:40:49.466804Z","iopub.status.idle":"2021-12-05T15:40:49.671556Z","shell.execute_reply.started":"2021-12-05T15:40:49.466764Z","shell.execute_reply":"2021-12-05T15:40:49.670438Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"ckpt_save_path4 = ckpt_manager4.save()\nprint ('\\nSaving checkpoint for epoch {} at {}'.format(301, ckpt_save_path4))  ","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:40:56.293960Z","iopub.execute_input":"2021-12-05T15:40:56.294617Z","iopub.status.idle":"2021-12-05T15:40:56.547678Z","shell.execute_reply.started":"2021-12-05T15:40:56.294573Z","shell.execute_reply":"2021-12-05T15:40:56.546791Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# !tar -zcvf finalModelv2.tar.gz ./checkpoints4\n!zip -r model.zip ./checkpoints4","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:42:19.989032Z","iopub.execute_input":"2021-12-05T15:42:19.989351Z","iopub.status.idle":"2021-12-05T15:42:36.440637Z","shell.execute_reply.started":"2021-12-05T15:42:19.989320Z","shell.execute_reply":"2021-12-05T15:42:36.439776Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"document_tokenizer\nsummary_tokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:42:49.828817Z","iopub.execute_input":"2021-12-05T15:42:49.829137Z","iopub.status.idle":"2021-12-05T15:42:49.834421Z","shell.execute_reply.started":"2021-12-05T15:42:49.829083Z","shell.execute_reply":"2021-12-05T15:42:49.833276Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"with open('document_tokenizer.pickle', 'wb') as handle:\n    pickle.dump(document_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:42:50.274543Z","iopub.execute_input":"2021-12-05T15:42:50.275034Z","iopub.status.idle":"2021-12-05T15:42:50.317723Z","shell.execute_reply.started":"2021-12-05T15:42:50.274994Z","shell.execute_reply":"2021-12-05T15:42:50.316865Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"with open('summary_tokenizer.pickle', 'wb') as handle:\n    pickle.dump(summary_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:42:50.725487Z","iopub.execute_input":"2021-12-05T15:42:50.726412Z","iopub.status.idle":"2021-12-05T15:42:50.742973Z","shell.execute_reply.started":"2021-12-05T15:42:50.726357Z","shell.execute_reply":"2021-12-05T15:42:50.742164Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"one = \"NEW DELHI: Starlink, the satellite internet division of billionaire Elon Musk's rocket company SpaceX, will apply early next year for a commercial licence in India to provide broadband and other services, its country head said.We hope to have applied for a commercial license on or before 31st January 2022 (unless we hit some major roadblock), Sanjay Bhargava, Starlink Country Director, India at SpaceX said in a LinkedIn post.If the company can roll out its services by April, it aims to have 200,000 Starlink devices in India by December 2022, it said in a presentation posted by Bhargava. The company has previously said it expects 80% of these devices to be in rural areas.Starlink is one of a growing number of companies launching small satellites as part of a low-Earth orbit network to provide low-latency broadband internet services around the world, with a particular focus on remote areas that terrestrial internet infrastructure struggles to reach.\"","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:49:08.825656Z","iopub.execute_input":"2021-12-05T15:49:08.825938Z","iopub.status.idle":"2021-12-05T15:49:08.830598Z","shell.execute_reply.started":"2021-12-05T15:49:08.825907Z","shell.execute_reply":"2021-12-05T15:49:08.829552Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"two = \"leaving his job as an Assistant Manager with Axis Bank, Aditya Bhalla, a native of Gurugram has joined Capgemini wherein he received a 200 per cent hike in his salary. How? By upskilling. Bhalla pursued an online course in artificial intelligence (AI) and Machine Learning (ML). From a CTC of Rs 6 lakhs, his annual income has now raised to Rs 18 lakh.After getting a decent rank in AIEEE, he pursued BTech in ECE from MMU Ambala and a PGDM from Manipal Bangalore. Thereafter, he joined Axis Bank, however, Aditya was not satisfied with his job and decided to do a PG programme in Artificial Intelligence and Machine Learning (PGP AIML) from Great Learning to upgrade his skills.\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"three = \"Indiaâs fifth Omicron case was detected in Delhi as a Tanzania returnee tested positive for the strain. Delhi health minister Satyendar Jain said the patient is currently undergoing treatment at Lok Nayak Hospital. Fifteen suspected patients of Omicron, who flew in the national capital from at risk countries are admitted to the Delhi governmentâs LNJP hospital, news agency PTI reported.\"","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:52:25.008167Z","iopub.execute_input":"2021-12-05T15:52:25.008768Z","iopub.status.idle":"2021-12-05T15:52:25.012822Z","shell.execute_reply.started":"2021-12-05T15:52:25.008731Z","shell.execute_reply":"2021-12-05T15:52:25.012125Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"four = \"If there are vacancies and also eligible candidates, why is there no recruitment, BJP MP Varun Gandhi asked today as he targeted the party-led Uttar Pradesh government over a police crackdown on a candlelight march by job seekers in Lucknow. The Pilibhit MP, who has been publicly expressing views that are at odds with the BJP's stand, shared a viral video in which policemen can be seen chasing and cane-charging protesters. Mr Gandhi said these protesters too are Indians and no one is ready to even hear their grievances. He also appealed to the authorities, asking if they would have been able to act in the same manner if their children were part of these protests.\"","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:53:57.339173Z","iopub.execute_input":"2021-12-05T15:53:57.339450Z","iopub.status.idle":"2021-12-05T15:53:57.344824Z","shell.execute_reply.started":"2021-12-05T15:53:57.339420Z","shell.execute_reply":"2021-12-05T15:53:57.343941Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"five = \"The global crypto market capitalisation is down 5.53 percent over the last 24 hours to stand at $2.3 trillion. The total crypto market volume over the last 24 hours is $203.74 billion, a 48.22 percent increase. The total volume in DeFi is currently $27.96 billion, 13.72 percent of the total crypto market 24-hour volume. The volume of all stable coins is now $162.40 billion, which is 79.71 percent of the total crypto market's 24-hour volume.\"","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:55:48.229537Z","iopub.execute_input":"2021-12-05T15:55:48.230381Z","iopub.status.idle":"2021-12-05T15:55:48.234230Z","shell.execute_reply.started":"2021-12-05T15:55:48.230341Z","shell.execute_reply":"2021-12-05T15:55:48.233399Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"six = \"Indian badminton ace P V Sindhu settled for a silver medal at the BWF World Tour Finals after going down meekly against Korean teen sensation An Seyoung in the summit clash, here on Sunday.Sindhu, the reigning world champion and two-time Olympic medallist, could neither match the pace nor breach the defence of the world number six Korean, losing 16-21 12-21 in the 40-minute lop-sided clash.\"","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:59:32.083848Z","iopub.execute_input":"2021-12-05T15:59:32.084134Z","iopub.status.idle":"2021-12-05T15:59:32.087876Z","shell.execute_reply.started":"2021-12-05T15:59:32.084088Z","shell.execute_reply":"2021-12-05T15:59:32.087024Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":" print(summarize(clean_words(one)))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:49:45.133814Z","iopub.execute_input":"2021-12-05T15:49:45.134090Z","iopub.status.idle":"2021-12-05T15:49:46.006094Z","shell.execute_reply.started":"2021-12-05T15:49:45.134059Z","shell.execute_reply":"2021-12-05T15:49:46.005372Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":" print(summarize(clean_words(\"leaving his job as an Assistant Manager with Axis Bank, Aditya Bhalla, a native of Gurugram has joined Capgemini wherein he received a 200 per cent hike in his salary. How? By upskilling. Bhalla pursued an online course in artificial intelligence (AI) and Machine Learning (ML). From a CTC of Rs 6 lakhs, his annual income has now raised to Rs 18 lakh.After getting a decent rank in AIEEE, he pursued BTech in ECE from MMU Ambala and a PGDM from Manipal Bangalore. Thereafter, he joined Axis Bank, however, Aditya was not satisfied with his job and decided to do a PG programme in Artificial Intelligence and Machine Learning (PGP AIML) from Great Learning to upgrade his skills.\")))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:48:33.461250Z","iopub.execute_input":"2021-12-05T15:48:33.461550Z","iopub.status.idle":"2021-12-05T15:48:34.507541Z","shell.execute_reply.started":"2021-12-05T15:48:33.461514Z","shell.execute_reply":"2021-12-05T15:48:34.506798Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":" print(summarize(clean_words(three)))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:52:42.566080Z","iopub.execute_input":"2021-12-05T15:52:42.566825Z","iopub.status.idle":"2021-12-05T15:52:43.323669Z","shell.execute_reply.started":"2021-12-05T15:52:42.566771Z","shell.execute_reply":"2021-12-05T15:52:43.322439Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":" print(summarize(clean_words(four)))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:54:15.597683Z","iopub.execute_input":"2021-12-05T15:54:15.598458Z","iopub.status.idle":"2021-12-05T15:54:16.463699Z","shell.execute_reply.started":"2021-12-05T15:54:15.598414Z","shell.execute_reply":"2021-12-05T15:54:16.462924Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":" print(summarize(clean_words(five)))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:55:58.214967Z","iopub.execute_input":"2021-12-05T15:55:58.215461Z","iopub.status.idle":"2021-12-05T15:55:59.132629Z","shell.execute_reply.started":"2021-12-05T15:55:58.215421Z","shell.execute_reply":"2021-12-05T15:55:59.131905Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":" print(summarize(clean_words(six)))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T15:59:47.204639Z","iopub.execute_input":"2021-12-05T15:59:47.204907Z","iopub.status.idle":"2021-12-05T15:59:48.433601Z","shell.execute_reply.started":"2021-12-05T15:59:47.204877Z","shell.execute_reply":"2021-12-05T15:59:48.432724Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(summarize(clean_words(\" Kindly forward the attached mail to all our students to actively participate in the events going to be conducted during Energy Conservation week.\")))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:04:08.692770Z","iopub.execute_input":"2021-12-05T16:04:08.693044Z","iopub.status.idle":"2021-12-05T16:04:09.514088Z","shell.execute_reply.started":"2021-12-05T16:04:08.693005Z","shell.execute_reply":"2021-12-05T16:04:09.513356Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"print(summarize(clean_words(\"Humans have an amazing ability to make sense of their surroundings using sound. For example, we routinely deal with situations like the ringing of the telephone in the office, the honking of a horn while driving and the sound made by the contents of a shaken box. Machine listening deals with creating algorithms which can perform similar tasks, and more. With varied applications like self- driving cars, intelligent assistive devices and enhanced human-computer interaction, machine listening brings together various domains like audio signal processing and modelling, artificial intelligence, cognitive science and acoustics.\")))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:05:24.201701Z","iopub.execute_input":"2021-12-05T16:05:24.202414Z","iopub.status.idle":"2021-12-05T16:05:24.947537Z","shell.execute_reply.started":"2021-12-05T16:05:24.202358Z","shell.execute_reply":"2021-12-05T16:05:24.946780Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"print(summarize(clean_words(\"Finding software solutions to professional technical issues will decide how well we perform in the days to come. Technology for sure is the driver today. In pursuit of such solutions India Police Hackathon 2019 is being organised by Karnataka State Police and co-hosted by RV College of Engineering, Bengaluru, on their campus. IEEE is the Knowledge Partner providing most of the Mentors and Jury. India Police Hackathon 2019 is scheduled to be on 16th and 17th November, a 36-hour Hackathon. It is an Open Hackathon with No Registration Fee and Online Elimination Round. Around 25 teams of 3 to 5 each will participate in the Hackathon, based on the Elimination Round.\")))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T16:07:43.808783Z","iopub.execute_input":"2021-12-05T16:07:43.809592Z","iopub.status.idle":"2021-12-05T16:07:44.718138Z","shell.execute_reply.started":"2021-12-05T16:07:43.809551Z","shell.execute_reply":"2021-12-05T16:07:44.717369Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}